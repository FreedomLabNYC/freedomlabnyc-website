<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Run your own AI inference server by renting GPU hardware and deploying open-source models with a web interface.">
    <title>Self-Hosting AI Models | Freedom Lab NYC</title>
    <link rel="icon" href="../../static/img/torch transparent icocrop2.png" type="image/png">
    <link rel="stylesheet" href="../../css/styles.css">
    <link rel="stylesheet" href="../../css/tutorial-page.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Press+Start+2P&family=Space+Grotesk:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=block" rel="stylesheet">
</head>
<body>
    <div class="mobile-overlay" id="mobileOverlay"></div>
    <header class="header">
        <a href="/" class="logo"><img src="../../static/img/FLNYC 2LINE+LOGO.png" alt="Freedom Lab NYC" class="logo-wide"></a>
        <nav class="nav-menu" id="navMenu">
            <a href="/classes-events/" class="nav-link">Classes & Events</a>
            <a href="/resources/" class="nav-link active">Resources</a>
            
            <a href="/contact/" class="nav-link">Contact</a>
            <a href="/donate/" class="nav-link">Donate</a>
            <a href="http://2iyutqpfixbdpgwd7so7zuodvqqanpjssv54fyqaessxfv6z3d7egjyd.onion" class="nav-link nav-link-onion" target="_blank">Onion Site</a>
            <a href="/join/" class="nav-btn">Join</a>
            
        </nav>
        <div class="hamburger" id="hamburger"><span></span><span></span><span></span></div>
    </header>
    <main class="tutorial-content">
        <div class="tutorial-support-banner green">
            <svg viewBox="0 0 32 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                <defs>
                    <linearGradient id="greenGradient" x1="0%" y1="0%" x2="0%" y2="100%">
                        <stop offset="0%" style="stop-color:#b8e986;stop-opacity:1" />
                        <stop offset="100%" style="stop-color:#5cb025;stop-opacity:1" />
                    </linearGradient>
                </defs>
                <g opacity="0.75">
                    <circle cx="7" cy="6" r="3.5" fill="url(#greenGradient)"/>
                    <ellipse cx="7" cy="15" rx="4" ry="5" fill="url(#greenGradient)"/>
                </g>
                <circle cx="16" cy="5" r="4.5" fill="url(#greenGradient)"/>
                <ellipse cx="16" cy="16" rx="5" ry="6" fill="url(#greenGradient)"/>
                <g opacity="0.75">
                    <circle cx="25" cy="6" r="3.5" fill="url(#greenGradient)"/>
                    <ellipse cx="25" cy="15" rx="4" ry="5" fill="url(#greenGradient)"/>
                </g>
            </svg>
            <p>These resources are written by Freedom Lab members. <a href="/join/">Join our Freedom Lab server</a> to be a part of the community and receive support directly.</p>
        </div>
        <div class="tutorial-header">
            <div class="tutorial-breadcrumb">
                <a href="/resources/">Resources</a><span>â€º</span><span>Self-Hosting AI Models</span>
            </div>
            <h1 class="tutorial-title">Self-Hosting AI Models</h1>
            <div class="tutorial-meta">
                <span class="tutorial-type-tag tutorial">Tutorial</span>
                <span class="tutorial-tag">Self-hosting</span>
                <span class="tutorial-tag">Privacy</span>
                <span class="tutorial-tag">Open-source AI</span>
                <span class="tutorial-tag">Linux</span>
            </div>
            <p class="tutorial-intro">Run your own AI inference server by renting GPU hardware and deploying open-source models with a web interface.</p>
            <p>This guide covers renting a GPU server on <a href="https://vast.ai" target="_blank">Vast.ai</a>, deploying models with <a href="https://ollama.com" target="_blank">Ollama</a>, and setting up <a href="https://openwebui.com" target="_blank">Open WebUI</a> with TLS.</p>
        </div>

        <nav class="tutorial-toc">
            <h3>Table of Contents</h3>
            <ol>
                <li><a href="#overview">Overview</a></li>
                <li><a href="#key-concepts">Key Concepts</a></li>
                <li><a href="#tools-used">Tools Used</a></li>
                <li><a href="#step-1-rent-a-server">Step 1 - Rent a Server</a></li>
                <li><a href="#step-2-ssh-into-the-server">Step 2 - SSH into the Server</a></li>
                <li><a href="#step-3-setup-ollama">Step 3 - Setup Ollama</a></li>
                <li><a href="#step-4-setup-open-webui">Step 4 - Setup Open WebUI</a></li>
                <li><a href="#step-5-setup-cloudflare">Step 5 - Setup Cloudflare</a></li>
                <li><a href="#step-6-setup-caddy">Step 6 - Setup Caddy</a></li>
                <li><a href="#step-7-access-and-configure">Step 7 - Access and Configure</a></li>
                <li><a href="#summary">Summary</a></li>
            </ol>
        </nav>

        <section class="tutorial-section" id="overview">
            <h2>Overview</h2>
            <ol>
                <li>Rent a server with GPUs on Vast.ai</li>
                <li>Download AI models with Ollama</li>
                <li>Setup a web interface for interacting with the models</li>
                <li>Add TLS support to distribute access securely</li>
            </ol>
        </section>

        <section class="tutorial-section" id="key-concepts">
            <h2>Key Concepts</h2>

            <h3>Inference</h3>
            <p>The process of using live data with a trained AI model to make predictions or solve tasks. This occurs after training, when the model is used for chatting or querying.</p>

            <h3>GGUF</h3>
            <p>GPT-Generated Unified Format (GGUF) is a specialized file format designed for optimized storage and fast loading of large language models (LLMs). It converts the original model file into a more efficient format, improving performance and usability during inference tasks.</p>

            <h3>Inference Framework</h3>
            <p>A software system optimized to execute trained AI models for real-world tasks. It handles:</p>
            <ul>
                <li>Loading models (e.g., GGUF or custom formats)</li>
                <li>Efficiently processing inputs/outputs</li>
                <li>Leveraging hardware (CPU/GPU) for speed</li>
            </ul>
            <p>Unlike training frameworks, it focuses purely on <strong>running models</strong> (not building them), prioritizing speed, compatibility, and ease of use.</p>
        </section>

        <section class="tutorial-section" id="tools-used">
            <h2>Tools Used</h2>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>Tool</th>
                            <th>Purpose</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Ollama</strong></td>
                            <td>Lightweight inference framework for downloading and running AI models</td>
                        </tr>
                        <tr>
                            <td><strong>Open WebUI</strong></td>
                            <td>ChatGPT-like web interface that integrates with Ollama's API</td>
                        </tr>
                        <tr>
                            <td><strong>Caddy</strong></td>
                            <td>Lightweight reverse proxy to handle TLS</td>
                        </tr>
                        <tr>
                            <td><strong>Cloudflare</strong></td>
                            <td>Domain registration and DNS API for TLS verification</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <section class="tutorial-section" id="step-1-rent-a-server">
            <h2>Step 1 - Rent a Server</h2>
            <ol>
                <li>Go to <a href="https://cloud.vast.ai/" target="_blank">Vast.ai</a></li>
                <li>Fund the account</li>
                <li>Select the template <strong>NVIDIA Cuda (Ubuntu)</strong></li>
                <li>Modify the template:
                    <ul>
                        <li>Open port 3000</li>
                        <li>Select launch mode <strong>Interactive shell server, SSH</strong></li>
                        <li>Check <strong>Use direct SSH connection</strong></li>
                        <li>Set at least 200 GB of disk space</li>
                    </ul>
                </li>
                <li>Save the template</li>
                <li>Go to <strong>Search</strong>:
                    <ul>
                        <li>Select the template</li>
                        <li>In Machine Options check <strong>Secure Cloud</strong> and <strong>Static IP Address</strong></li>
                        <li>Select a server with your desired GPU configuration</li>
                    </ul>
                </li>
            </ol>
        </section>

        <section class="tutorial-section" id="step-2-ssh-into-the-server">
            <h2>Step 2 - SSH into the Server</h2>
            <p>Go to <strong>Instances</strong> and click on the server IP. Note the IP and port mapping:</p>
            <pre><code>Public IP Address: &lt;SERVER_IP&gt;

Open Ports:
&lt;SERVER_IP&gt;:&lt;SSH_PORT&gt; -> 22/tcp
&lt;SERVER_IP&gt;:&lt;WEB_PORT&gt; -> 3000/tcp</code></pre>
            <p>The ports are automatically proxied by Vast.ai.</p>
            <p>Create an SSH keypair:</p>
            <pre><code>ssh-keygen -t ed25519</code></pre>
            <p>Back on your instance, click the Key icon and add your SSH public key.</p>
            <p>Connect to the server:</p>
            <pre><code>ssh -i ~/.ssh/id_ed25519 root@&lt;SERVER_IP&gt; -p &lt;SSH_PORT&gt;</code></pre>
            <p>Disable the preset tmux (optional):</p>
            <pre><code>touch .no_auto_tmux</code></pre>
        </section>

        <section class="tutorial-section" id="step-3-setup-ollama">
            <h2>Step 3 - Setup Ollama</h2>
            <p>Download and install Ollama:</p>
            <pre><code>curl -fsSL https://ollama.com/install.sh | sh</code></pre>
            <p>Verify the installation:</p>
            <pre><code>ollama --version</code></pre>
            <p>Download the models you want:</p>
            <pre><code>ollama pull deepseek-r1:7b</code></pre>
            <p>Browse available models at <a href="https://ollama.com/search" target="_blank">ollama.com/search</a></p>
            <p>Since we're inside a container without systemd, use tmux to keep Ollama running:</p>
            <pre><code>tmux new-session -s 'ollama'
ollama serve</code></pre>
            <p>Press <code>Ctrl+b d</code> to detach. Ollama is now running and exposes its API on port 11434.</p>
        </section>

        <section class="tutorial-section" id="step-4-setup-open-webui">
            <h2>Step 4 - Setup Open WebUI</h2>
            <p>Install uv (Python package manager):</p>
            <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh</code></pre>
            <p>Create the data directory:</p>
            <pre><code>mkdir ~/.open-webui</code></pre>
            <p>Open a tmux session and start Open WebUI on port 3001:</p>
            <pre><code>tmux new-session -s 'webui'
DATA_DIR=~/.open-webui uvx --python 3.11 open-webui@latest serve --port 3001</code></pre>
            <p>We use port 3001 because Caddy will handle TLS on port 3000 and proxy to 3001.</p>
            <p>Press <code>Ctrl+b d</code> to detach.</p>
        </section>

        <section class="tutorial-section" id="step-5-setup-cloudflare">
            <h2>Step 5 - Setup Cloudflare</h2>
            <ol>
                <li>Go to Cloudflare and register a domain (or use an existing one)</li>
                <li>Go to <strong>My Profile > API Tokens</strong></li>
                <li>Create a Token:
                    <ul>
                        <li>Select <strong>Create custom token</strong></li>
                        <li>Give the token a name</li>
                        <li>Set permissions: <strong>Zone : DNS : Edit</strong></li>
                    </ul>
                </li>
                <li>Save the API token</li>
            </ol>
            <p>This token allows Caddy to verify domain ownership via DNS challenge (since ports 80/443 may not be available).</p>
        </section>

        <section class="tutorial-section" id="step-6-setup-caddy">
            <h2>Step 6 - Setup Caddy</h2>
            <p>Download Caddy with the Cloudflare DNS plugin:</p>
            <ol>
                <li>Go to <a href="https://caddyserver.com/download" target="_blank">caddyserver.com/download</a></li>
                <li>Select <strong>Linux AMD64</strong></li>
                <li>Add the <code>caddy-dns/cloudflare</code> plugin</li>
                <li>Copy the download link</li>
            </ol>
            <p>On the server:</p>
            <pre><code>wget "&lt;DOWNLOAD_URL&gt;" -O /usr/bin/caddy
chmod +x /usr/bin/caddy</code></pre>
            <p>Verify the installation:</p>
            <pre><code>caddy version</code></pre>
            <p>Create the configuration directory and file:</p>
            <pre><code>mkdir -p /etc/caddy</code></pre>
            <p>Create <code>/etc/caddy/Caddyfile</code> with the following content:</p>
            <pre><code>example.com:3000 {
    tls {
        dns cloudflare {env.CLOUDFLARE_API_TOKEN}
    }
    reverse_proxy localhost:3001
}</code></pre>
            <p>Replace <code>example.com</code> with your domain.</p>
            <p>Start Caddy in a tmux session:</p>
            <pre><code>tmux new-session -s 'caddy'
CLOUDFLARE_API_TOKEN="YOUR_API_TOKEN" caddy run --config /etc/caddy/Caddyfile</code></pre>
            <p>Press <code>Ctrl+b d</code> to detach.</p>
        </section>

        <section class="tutorial-section" id="step-7-access-and-configure">
            <h2>Step 7 - Access and Configure</h2>
            <p>Access Open WebUI at <code>https://example.com:&lt;WEB_PORT&gt;/</code></p>
            <p>The first user to register becomes the admin. Configure user management:</p>
            <ul>
                <li>Create groups to manage permissions</li>
                <li>By default, AI models are private</li>
                <li>Grant access to specific groups or make models public</li>
            </ul>
        </section>

        <section class="tutorial-section" id="summary">
            <h2>Summary</h2>
            <p>Your self-hosted AI server is now running with:</p>
            <ul>
                <li><strong>Ollama</strong> serving models on port 11434 (internal)</li>
                <li><strong>Open WebUI</strong> on port 3001 (internal)</li>
                <li><strong>Caddy</strong> handling TLS on port 3000</li>
                <li>Models accessible via <code>https://your-domain.com:&lt;WEB_PORT&gt;/</code></li>
            </ul>
        </section>

        <nav class="tutorial-nav">
            <a href="/resources/" class="tutorial-nav-btn"><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M19 12H5M12 19l-7-7 7-7"/></svg>Back to Tutorials</a>
        </nav>
    </main>
    <footer class="site-footer">
        <div class="footer-social">
            <a href="/contact/" class="footer-social-link" aria-label="Email"><svg viewBox="0 0 24 24" fill="currentColor" class="footer-social-svg"><path d="M20 4H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/></svg></a>
            <a href="https://primal.net/p/nprofile1qqsrzwgcg39ck26lc3e2yfjhntgcecnlgy9evsuxrfsxx6p46r5s3pgzdvhyj" target="_blank" class="footer-social-link" aria-label="Nostr"><img src="../../static/img/nostr_logo.png" alt="Nostr" class="footer-social-icon"></a>
            <a href="https://x.com/freedomlabnyc" target="_blank" class="footer-social-link" aria-label="X"><svg viewBox="0 0 24 24" fill="currentColor" class="footer-social-svg"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg></a>
            <a href="https://www.linkedin.com/company/freedom-lab-nyc/" target="_blank" class="footer-social-link" aria-label="LinkedIn"><svg viewBox="0 0 24 24" fill="currentColor" class="footer-social-svg"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg></a>
        </div>
    </footer>
    <script>
        const hamburger = document.getElementById('hamburger');
        const navMenu = document.getElementById('navMenu');
        const mobileOverlay = document.getElementById('mobileOverlay');
        hamburger.addEventListener('click', () => {
            hamburger.classList.toggle('active');
            navMenu.classList.toggle('active');
            mobileOverlay.classList.toggle('active');
            document.body.style.overflow = navMenu.classList.contains('active') ? 'hidden' : '';
        });
        mobileOverlay.addEventListener('click', () => {
            hamburger.classList.remove('active');
            navMenu.classList.remove('active');
            mobileOverlay.classList.remove('active');
            document.body.style.overflow = '';
        });
        // Image lightbox
        const lightbox = document.createElement('div');
        lightbox.className = 'lightbox-overlay';
        lightbox.innerHTML = '<img src="" alt="">';
        document.body.appendChild(lightbox);
        const lightboxImg = lightbox.querySelector('img');
        document.querySelectorAll('.tutorial-section img, .tutorial-header img, .callout-content img').forEach(img => {
            img.addEventListener('click', () => {
                lightboxImg.src = img.src;
                lightboxImg.alt = img.alt;
                lightbox.classList.add('active');
                document.body.style.overflow = 'hidden';
            });
        });
        lightbox.addEventListener('click', () => {
            lightbox.classList.remove('active');
            document.body.style.overflow = '';
        });
    </script>
</body>
</html>
